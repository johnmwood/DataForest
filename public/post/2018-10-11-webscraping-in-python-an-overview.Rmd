---
title: Webscraping in Python - a Workflow 
author: John Wood
date: '2018-10-11'
slug: webscraping-in-python-a-workflow
type: "post" 
image: "post/img/requests.png"
showonlyimage: false
weight: 2
description: "Scraping data off the web only requires some knowledge of the available options in Python and a little creativity"
categories: []
tags: []
authors: []
---
```{r setup, include = FALSE}
knitr::knit_engines$set(python = reticulate::eng_python)
```

Webscraping in Python is not only incredibly satisfying to implement but also allows us to be creative in the way we want to approach any given site. Just as jazz improv requires understanding of scales and chord structure to be able to properly add to the progression, scraping data off the internet requires knowledge of the available options to be able to effectively scrap data. 

### Web Backend Briefly Explained 

For anyone who doesn't have experience with web development, it is important to understand how data is transferred to the user. Your computer talks to a site's server through requests. In particular, there are some requests which are generally required for a server to make: GET (read data), POST (create new data), and DELETE. We are going to use Python to make requests from a script, take the data, and manipulate it to put together a dataset. 

### Static HTML Sites

The web is largely made up of complicated web applications generated by a JavaScript framework, sites which are usually much harder to scrape. Some websites, however, remain simpler so we want to keep our options open. **As a general rule of thumb, sites which primarily display data will tend to be a little easier to scrape.** [Yahoo Finance](https://finance.yahoo.com/sector/technology) is a good example of this. The site doesn't require a complicated interface or application, its primary purpose is to give the user stock data. Let's see if we can turn that stock data into anything useful? 

```{python eval=FALSE}
from bs4 import BeautifulSoup
import requests 


url = "https://finance.yahoo.com/sector/technology" 
r = requests.get(url) 
soup = BeautifulSoup(r.content, "html.parser")

print(soup.title)
```

```{python eval=FALSE}
table = soup.find_all("table")[1].find("tbody")
```

```{python eval=FALSE}
def create_stock(row):
    fields = ["symbol", "name", "price", "change", "change_percent",
              "volume", "three_month_avg_vol", "market_cap", "PE_ratio"]
    data = [x.text for x in row]

    return {key: value for key, value in zip(fields, data)}
    
all_stocks = [] 
for row in table: 
    stock = create_stock(row)
    all_stocks.append(stock)
    
print(len(all_stocks))
print(all_stocks)
```


